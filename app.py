import streamlit as st
import time
import json
import os
import google.generativeai as genai
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from dotenv import load_dotenv

# âœ… Load API Key Securely
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

if not api_key:
    st.error("âš ï¸ **API KEY not found**â—â—â— Please add your Google API key to the `.env` file.")
    st.stop()

# âœ… Initialize Google API and AI Model
chat_model = ChatGoogleGenerativeAI(model="gemini-1.5-flash", google_api_key=api_key)

# âœ… Chat History Functions
CHAT_DIR = "chat_history"
os.makedirs(CHAT_DIR, exist_ok=True)

def get_chat_history(username):
    """Load chat history from a file."""
    try:
        with open(f"{CHAT_DIR}/{username}.json", "r") as hfile:
            return json.load(hfile)
    except (FileNotFoundError, json.JSONDecodeError):
        return []

def save_chat_history(username):
    """Save chat history to a file."""
    with open(f"{CHAT_DIR}/{username}.json", "w") as hfile:
        json.dump(st.session_state.chat_history, hfile, indent=4)

def delete_chat_history(username):
    """Delete chat history for a user."""
    try:
        os.remove(f"{CHAT_DIR}/{username}.json")
        st.session_state.chat_history = []
        st.success("âœ… Chat history deleted successfully.")
    except FileNotFoundError:
        st.warning("âš ï¸ No chat history found to delete.")

def download_chat_history(username):
    """Download chat history as a text file."""
    chat_history = get_chat_history(username)
    if chat_history:
        chat_text = "\n".join([f"User: {chat['user']}\nAI: {chat['ai']}\n" for chat in chat_history])
        st.download_button(
            label="â¬‡ï¸ Download Chat History",
            data=chat_text,
            file_name=f"{username}_chat_history.txt",
            mime="text/plain"
        )
    else:
        st.warning("âš ï¸ No chat history available to download.")

# âœ… Streamlit Page Config
st.set_page_config(page_title="Data Science AI Tutor", page_icon="ğŸ¤–", layout="centered")

# âœ… User Authentication
if "login" not in st.session_state:
    st.session_state.login = False

if not st.session_state.login:
    st.title("ğŸ¤– Data Science Tutor")
    username = st.text_input("Enter your username:")
    if st.button("Login"):
        if not username:
            st.error("âš ï¸ Please enter a username.")
        else:
            st.session_state.name = username
            st.session_state.login = True
            st.session_state.chat_history = get_chat_history(username)
            st.success("âœ… Chat history loaded!" if st.session_state.chat_history else "ğŸ†• New session started.")
            time.sleep(1)
            st.rerun()
    st.stop()

# âœ… Sidebar for User Info and Chat Controls
username = st.session_state.name
with st.sidebar:
    st.write(f"### ğŸ‘‹ Hello, {username.title()}! ğŸ‰")
    st.write("""
#### Welcome to the AI Data Science Tutor ğŸ¤–
I can help with:
- ğŸ§  Machine Learning
- ğŸ“Š Data Analysis & Visualization
- ğŸ¤– AI & Deep Learning
- ğŸ“ Python for Data Science
""")
    if st.button("ğŸ—‘ Delete Chat History"):
        delete_chat_history(username)
    download_chat_history(username)

# âœ… Display Chat History
if not st.session_state.chat_history:
    st.chat_message("assistant").write("ğŸ’¡ **Tip:** Ask me anything related to **data science**!")
else:
    for chat in st.session_state.chat_history:
        with st.chat_message("user"):
            st.markdown(f"**ğŸ§‘â€ğŸ’» User:** {chat['user']}")
        with st.chat_message("assistant"):
            st.markdown(f"**ğŸ¤– AI:** {chat['ai']}")

# âœ… AI Chat Prompt Template
chat_prompt = ChatPromptTemplate(
    messages=[
        ("system", """
        You are a Data Science AI Tutor. Your job is to:
        - Answer **ONLY** data science-related questions.
        - Provide structured answers with **examples, bullet points, and code snippets** if needed.
        - If a question is **not related** to data science, respond with:
          "I am unable to answer that question. Please ask something related to data science."
        """),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{user_input}")
    ],
)

# âœ… AI Processing Chain
output_parser = StrOutputParser()
runnable_get_history = RunnableLambda(get_chat_history)
chain = RunnablePassthrough.assign(history=runnable_get_history) | chat_prompt | chat_model | output_parser

# âœ… Chat Input with Streaming AI Response
user_input = st.chat_input("ğŸ’¬ Ask a Data Science question...")

if user_input:
    with st.chat_message("user"):
        st.markdown(f"**ğŸ§‘â€ğŸ’» User:** {user_input}")

    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        response_text = ""
        
        with st.spinner("ğŸ¤” AI is thinking..."):
            try:
                ai_response = chain.invoke({"user_input": user_input})
                for word in ai_response.split():
                    response_text += word + " "
                    time.sleep(0.03)  # Simulate real-time typing
                    response_placeholder.markdown(response_text)

                # Save chat history
                st.session_state.chat_history.append({"user": user_input, "ai": response_text})
                save_chat_history(username)
                st.rerun()

            except Exception as e:
                st.error(f"âš ï¸ AI Error: {e}")
